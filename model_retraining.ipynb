{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at e:\\swe\\python3.11.5\\lib\\site-packages\\vboxapi-1.0-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\n"
     ]
    }
   ],
   "source": [
    "pip -q install --upgrade ruptures scikit-learn tqdm matplotlib joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "from datetime import date, datetime, timedelta\n",
    "import datetime as dt\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "from scipy.stats import kurtosis, skew\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import joblib\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "\n",
    "import ruptures as rpt\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Folders for Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_training_data_path = 'Model_Training_Data/'\n",
    "model_path = 'Models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(model_training_data_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load CSV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_data_csv(base_path):\n",
    "    combined_df_original = pd.DataFrame()  # Initialize an empty DataFrame\n",
    "\n",
    "    # Check if the folder exists\n",
    "    if os.path.exists(base_path) and os.path.isdir(base_path):\n",
    "        \n",
    "        all_files = os.listdir(base_path)\n",
    "\n",
    "        # Filter only CSV files\n",
    "        csv_files = [file for file in all_files if file.endswith('.CSV')]\n",
    "\n",
    "        for file in tqdm(csv_files, desc=\"Processing Files\"):\n",
    "            df_original = pd.read_csv(os.path.join(base_path, file))\n",
    "\n",
    "            # Select desired columns\n",
    "            selected_columns = ['Object Temperature(C)', 'Heart Rate Ear(BPM)', 'GSR', 'Stress_Score']\n",
    "            df_original = df_original[selected_columns]\n",
    "\n",
    "            # Concatenate into the combined DataFrame\n",
    "            combined_df_original = pd.concat([combined_df_original, df_original], ignore_index=True)\n",
    "\n",
    "    # Rename the columns\n",
    "    combined_df_original = combined_df_original.rename(columns={\n",
    "        'Object Temperature(C)': 'TEMP',\n",
    "        'Heart Rate Ear(BPM)': 'HR',\n",
    "        'GSR': 'EDA',\n",
    "        'Stress_Score': 'STRESS_SCORE'\n",
    "    })\n",
    "\n",
    "    # Export the combined DataFrame to a CSV file\n",
    "    combined_df_original.to_csv(f'{base_path}combined_collected_df_original.csv', index=False)\n",
    "    print(\"CSV File saved successfully: \", combined_df_original.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Files: 100%|██████████| 38/38 [00:00<00:00, 189.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV File saved successfully:  (12084, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "all_data_csv(model_training_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Raw Data\n",
    "\n",
    "- remove rows with HR values of 0\n",
    "- convert GSR values to EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert GSR to EDA\n",
    "def calculate_eda_value(gsr_value):\n",
    "    Serial_Port_Reading = gsr_value\n",
    "    resistance = ((1024 + 2 * Serial_Port_Reading) * 10000) / (512 - Serial_Port_Reading)\n",
    "    eda_value = (1 / resistance) * 1e6\n",
    "    return eda_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_csv(base_path):\n",
    "\n",
    "    combined_df_original = pd.read_csv(base_path)\n",
    "\n",
    "    # Filter rows where 'HR' column is not equal to 0\n",
    "    preprocessed_df = combined_df_original[combined_df_original['HR'] != 0]\n",
    "    \n",
    "    # Convert GSR to EDA\n",
    "    preprocessed_df['EDA'] = preprocessed_df['EDA'].apply(calculate_eda_value)\n",
    "    \n",
    "    return preprocessed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maria\\AppData\\Local\\Temp\\ipykernel_9376\\2433022789.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  preprocessed_df['EDA'] = preprocessed_df['EDA'].apply(calculate_eda_value)\n"
     ]
    }
   ],
   "source": [
    "preprocessed_df = preprocess_csv(f'{model_training_data_path}combined_collected_df_original.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statistical_features(arr):\n",
    "    vmin = np.amin(arr)\n",
    "    vmax = np.amax(arr)\n",
    "    mean = np.mean(arr)\n",
    "    std = np.std(arr)\n",
    "    return vmin, vmax, mean, std\n",
    "\n",
    "def shape_features(arr):\n",
    "    skewness = skew(arr)\n",
    "    kurt = kurtosis(arr)\n",
    "    return skewness, kurt\n",
    "\n",
    "def calculate_rms(signal):\n",
    "    diff_squared = np.square(np.ediff1d(signal))\n",
    "    rms_value = np.sqrt(np.mean(diff_squared))\n",
    "    return rms_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extended Features\n",
    "\n",
    "- iterating with a step size of 20\n",
    "- taking 40 rows at a time to generate a single row of df_features\n",
    "- find_peaks() : identify peaks in the EDA signal (eda) using the function and then count the number of detected peaks using len() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(data):\n",
    "    cols = [\n",
    "        'EDA_Mean', 'EDA_Min', 'EDA_Max', 'EDA_Std', 'EDA_Kurtosis', 'EDA_Skew', 'EDA_Num_Peaks', 'EDA_Amplitude', 'EDA_Duration',\n",
    "        'HR_Mean', 'HR_Min', 'HR_Max', 'HR_Std', 'HR_RMS', 'TEMP_Mean', 'TEMP_Min', 'TEMP_Max', 'TEMP_Std', 'STRESS_SCORE'\n",
    "    ]\n",
    "\n",
    "    df_features = pd.DataFrame(columns=cols)\n",
    "    index = 0\n",
    "\n",
    "    for i in tqdm(range(0, len(data['EDA']), 20), desc=\"Processing rows\", leave=True):\n",
    "        \n",
    "        df_partial = data.iloc[i:i+40,]\n",
    "        plen = len(df_partial['EDA'])\n",
    "\n",
    "        if plen < 40:\n",
    "            continue\n",
    "\n",
    "        eda = df_partial['EDA'].values\n",
    "        hr = df_partial['HR'].values\n",
    "        temp = df_partial['TEMP'].values\n",
    "        stress_score = df_partial['STRESS_SCORE'].values\n",
    "\n",
    "        eda_min, eda_max, eda_mean, eda_std = statistical_features(eda)\n",
    "        hr_min, hr_max, hr_mean, hr_std = statistical_features(hr)\n",
    "        temp_min, temp_max, temp_mean, temp_std = statistical_features(temp)\n",
    "        stress_score_min, stress_score_max, stress_score_mean, stress_score_std = statistical_features(stress_score)\n",
    "        eda_skew, eda_kurtosis = shape_features(eda)\n",
    "\n",
    "        hr_rms = calculate_rms(hr)\n",
    "        temp_rms = calculate_rms(temp)\n",
    "\n",
    "        peaks, properties = find_peaks(eda, width=5)\n",
    "        num_Peaks = len(peaks)\n",
    "\n",
    "        prominences = np.array(properties['prominences'])\n",
    "        widths = np.array(properties['widths'])\n",
    "        amplitude = np.sum(prominences)\n",
    "        duration = np.sum(widths)\n",
    "\n",
    "        df_features.loc[index] = [eda_mean, eda_min, eda_max, eda_std, eda_kurtosis, eda_skew, num_Peaks, amplitude,\n",
    "                                  duration, hr_mean, hr_min, hr_max, hr_std, hr_rms, temp_mean, temp_min, temp_max, temp_std, stress_score_mean]\n",
    "\n",
    "        index = index + 1\n",
    "\n",
    "    return df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  23%|██▎       | 134/595 [00:00<00:02, 224.55it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows: 100%|██████████| 595/595 [00:02<00:00, 271.06it/s]\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "df_features = extract_features(preprocessed_df)\n",
    "warnings.resetwarnings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(593, 19)\n"
     ]
    }
   ],
   "source": [
    "print(df_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lag Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_lag_features(input_df, columns, lags):\n",
    "    cols = list(map(str, range(len(columns) * len(lags), 0, -1)))\n",
    "    lag_df = pd.DataFrame(columns=cols)\n",
    "\n",
    "    index = len(columns) * len(lags)\n",
    "\n",
    "    for col in tqdm(columns, desc=\"Generating lag features\", leave=True):\n",
    "        for lag in tqdm(lags, desc=f\"Lag features for {col}\", leave=True):\n",
    "            lagged_column = f'{index}'\n",
    "            lag_df[lagged_column] = input_df[col].shift(lag)\n",
    "            index -= 1\n",
    "            \n",
    "    return lag_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lag features for HR_Mean: 100%|██████████| 10/10 [00:00<00:00, 999.64it/s]\n",
      "Lag features for TEMP_Mean: 100%|██████████| 10/10 [00:00<00:00, 1110.99it/s]\n",
      "Lag features for EDA_Mean: 100%|██████████| 10/10 [00:00<00:00, 1111.16it/s]\n",
      "Generating lag features: 100%|██████████| 3/3 [00:00<00:00, 62.50it/s]\n"
     ]
    }
   ],
   "source": [
    "cols = ['HR_Mean', 'TEMP_Mean', 'EDA_Mean']\n",
    "lags = [10, 9, 8, 7, 6, 5, 4, 3, 2, 1]\n",
    "\n",
    "df_lag_features = generate_lag_features(df_features, cols, lags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(593, 30)\n"
     ]
    }
   ],
   "source": [
    "print(df_lag_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total = pd.concat([df_lag_features, df_features], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(593, 49)\n"
     ]
    }
   ],
   "source": [
    "print(df_total.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_features(df_total, feature_columns):\n",
    "    scaled_df = df_total.copy()\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_df[feature_columns] = scaler.fit_transform(scaled_df[feature_columns])\n",
    "    scaled_df = scaled_df.fillna(0)\n",
    "    return scaled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_label_regression(df_total, label_column):\n",
    "    scaled_df = df_total.copy()\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_df[label_column] = scaler.fit_transform(scaled_df[label_column].values.reshape(-1, 1))\n",
    "    scaled_df = scaled_df.fillna(0)\n",
    "    return scaled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_label_classifier(df_total, label_column):\n",
    "    df_total[label_column] = df_total[label_column].apply(lambda x: 0 if x <= 3.25 else (1 if 3.25 < x <= 6.5 else 2))\n",
    "    return df_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = df_total.columns[:48]\n",
    "df_total_scaled_r = scale_features(df_total, feature_cols)\n",
    "df_total_scaled_r = scale_label_regression(df_total_scaled_r, 'STRESS_SCORE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = df_total.columns[:48]\n",
    "df_total_scaled_c = scale_features(df_total, feature_cols)\n",
    "df_total_scaled_c = scale_label_classifier(df_total_scaled_c, 'STRESS_SCORE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final CSV File for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total_scaled_r.to_csv(f'{model_training_data_path}scaled_collected_df_total_regression.csv', index=False)\n",
    "df_total_scaled_c.to_csv(f'{model_training_data_path}scaled_collected_df_total_classifier.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(593, 49) (593, 49)\n"
     ]
    }
   ],
   "source": [
    "print(df_total_scaled_r.shape, df_total_scaled_c.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stress detection model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_from_folder(folder_path, keyword):\n",
    "\n",
    "    all_files = os.listdir(folder_path)\n",
    "    keyword_files = [file for file in all_files if keyword in file and \"Retrained\" not in file and file.endswith(\".pkl\")]\n",
    "\n",
    "    if len(keyword_files) > 0:\n",
    "        \n",
    "        # Sort files based on date_time in the filename\n",
    "        sorted_files = sorted(\n",
    "            keyword_files,\n",
    "            key=lambda x: datetime.strptime(\"_\".join(x.split(\"_\")[-3:]).replace(\".pkl\", \"\"), \"%Y_%m_%d\"),\n",
    "            reverse=True\n",
    "        )\n",
    "\n",
    "        selected_file = sorted_files[0]\n",
    "        file_path = os.path.join(folder_path, selected_file)\n",
    "\n",
    "        # Load the model from the selected pkl file\n",
    "        with open(file_path, 'rb') as file:\n",
    "            loaded_model = joblib.load(file)\n",
    "\n",
    "        print(f\"Loaded model from {selected_file}\")\n",
    "        return loaded_model\n",
    "    else:\n",
    "        print(f\"No pkl file with '{keyword}' in its name found in the folder.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(f'{model_training_data_path}scaled_collected_df_total_regression.csv')\n",
    "\n",
    "X_r = data.iloc[:,0:48] # features\n",
    "Y_r = data.iloc[:,48:49] # labels\n",
    "\n",
    "X_train_r, X_val_r, Y_train_r, Y_val_r = train_test_split(X_r, Y_r, test_size=0.33, random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from Regressor_Date_Time_2024_01_15.pkl\n"
     ]
    }
   ],
   "source": [
    "regressor = load_model_from_folder(model_path, keyword=\"Regressor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(max_depth=15)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(max_depth=15)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(max_depth=15)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.fit(X_train_r, Y_train_r.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(f'{model_training_data_path}scaled_collected_df_total_classifier.csv')\n",
    "\n",
    "X_c = data.iloc[:,0:48] # features\n",
    "Y_c = data.iloc[:,48:49] # labels\n",
    "\n",
    "X_train_c, X_val_c, Y_train_c, Y_val_c = train_test_split(X_c, Y_c, test_size=0.33, random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from Classifier_Date_Time_2024_01_15.pkl\n"
     ]
    }
   ],
   "source": [
    "clf = load_model_from_folder(model_path, keyword=\"Classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=15)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=15)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=15)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train_c, Y_train_c.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_format = '%Y_%m_%d'  # Format for extracting only the date\n",
    "current_date_time_dt = dt.datetime.now()  # Current Date and Time in a DateTime Object.\n",
    "current_date_string = dt.datetime.strftime(current_date_time_dt, date_format) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# naming system for model\n",
    "model_file_name_r = f'Retrained_Regressor_Date_Time_{current_date_string}.pkl'\n",
    "model_save_path_r = model_path + model_file_name_r\n",
    "\n",
    "# saving the model\n",
    "with open(model_save_path_r, 'wb') as file:\n",
    "    pickle.dump(regressor, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# naming system for model\n",
    "model_file_name_c = f'Retrained_Classifier_Date_Time_{current_date_string}.pkl'\n",
    "model_save_path_c = model_path + model_file_name_c\n",
    "\n",
    "# saving the model\n",
    "with open(model_save_path_c, 'wb') as file:\n",
    "    pickle.dump(clf, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_r = regressor.predict(X_val_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared Score: 0.8213688475090511\n"
     ]
    }
   ],
   "source": [
    "score = regressor.score(X_val_r, Y_val_r)\n",
    "print(f'R-squared Score: {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_c = clf.predict(X_val_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc = 0.9795918367346939\n",
      "pre = 0.9908045977011494\n",
      "recall = 0.9547619047619048\n",
      "f1 = 0.9718656136566585\n"
     ]
    }
   ],
   "source": [
    "f1score   = f1_score        (Y_val_c, Y_pred_c, average = 'macro')\n",
    "recall    = recall_score    (Y_val_c, Y_pred_c, average = 'macro')\n",
    "precision = precision_score (Y_val_c, Y_pred_c, average = 'macro')\n",
    "accuracy  = accuracy_score  (Y_val_c, Y_pred_c)\n",
    "\n",
    "print('acc =', accuracy)\n",
    "print('pre =', precision)\n",
    "print('recall =', recall) \n",
    "print('f1 =', f1score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
